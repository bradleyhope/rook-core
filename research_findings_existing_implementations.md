# Research Findings: Existing Implementations and Gaps to Invent

**Date:** November 9, 2025  
**Focus:** What's been built, what works, what's missing for ROOK

---

## Overview of Existing Systems

After comprehensive research, I've identified three major categories of production memory systems for AI agents:

1. **Mem0** - Memory extraction and consolidation
2. **MemGPT** - OS-inspired virtual context management
3. **Stanford Generative Agents** - Reflection-based memory with weighted retrieval

---

## 1. Mem0: Production-Ready Memory Extraction

**Source:** Chhikara et al. (2025) - arXiv:2504.19413

### What They Built:

#### Core Architecture:

```
EXTRACTION PHASE:
- Input: Message pair (mt-1, mt)
- Context: Conversation summary + recent messages
- Process: LLM extracts salient memories Œ© = {œâ1, œâ2, ..., œân}
- Output: Candidate facts for knowledge base

UPDATE PHASE:
- For each extracted fact œâi:
  1. Retrieve top s semantically similar existing memories
  2. LLM determines operation via "tool call":
     - ADD: Create new memory (no conflict)
     - UPDATE: Modify existing memory (refinement)
     - DELETE: Remove outdated memory (contradiction)
     - NOOP: Skip (redundant)
  3. Execute operation in database
```

#### Enhanced Variant: Mem0^g (Graph Memory):

- Memories stored as directed labeled graphs
- Entities as nodes, relationships as edges
- Enables multi-hop reasoning across connected facts
- Example: "John works at Company X" + "Company X acquired Company Y" ‚Üí "John's company acquired Company Y"

### Performance Results:

- **26% improvement** over OpenAI's memory system (LLM-as-a-Judge metric)
- **91% lower p95 latency** vs. full-context approach
- **90% token cost savings** vs. full-context approach
- Consistent performance across question types:
  - Single-hop queries
  - Temporal queries
  - Multi-hop queries
  - Open-domain queries

### Key Innovations:

1. **Incremental Processing**: Processes message pairs as they arrive (not batch)
2. **Asynchronous Summary Generation**: Background thread updates conversation summary
3. **LLM-Driven Memory Operations**: Model decides ADD/UPDATE/DELETE/NOOP
4. **Graph-Based Relationships**: Explicit entity-relation-entity triples

### What's Missing for ROOK:

‚ùå **No personality emergence** - Memories are facts, not experiences  
‚ùå **No importance weighting** - All memories treated equally  
‚ùå **No recency decay** - Old memories don't fade  
‚ùå **No reflection/consolidation** - No higher-level insights  
‚ùå **No sleep cycles** - Continuous processing only  
‚ùå **No emotional valence** - Facts are neutral  

---

## 2. MemGPT: OS-Inspired Virtual Context Management

**Source:** Packer et al. (2023) - arXiv:2310.08560

### What They Built:

#### Core Concept: LLM as Operating System

**Inspiration:** Traditional OS memory hierarchy (RAM ‚Üí Disk)

```
MAIN CONTEXT (Limited, ~8K tokens):
‚îú‚îÄ‚îÄ System Instructions (persona, functions)
‚îú‚îÄ‚îÄ Core Memory (editable scratchpad)
‚îÇ   ‚îú‚îÄ‚îÄ Human (user information)
‚îÇ   ‚îî‚îÄ‚îÄ Persona (agent identity)
‚îî‚îÄ‚îÄ Recall Storage (conversation history buffer)

EXTERNAL CONTEXT (Unlimited):
‚îî‚îÄ‚îÄ Archival Storage (long-term memory database)
```

#### Virtual Context Management:

**The Key Insight:** LLM manages its own memory via function calls

```python
# LLM has access to these functions:

def core_memory_append(name, content):
    """Add to core memory (human or persona)"""
    # Stays in main context (always visible)
    
def core_memory_replace(name, old_content, new_content):
    """Update core memory"""
    # Modify what's in main context
    
def archival_memory_insert(content):
    """Store in long-term archival memory"""
    # Moves to external storage (vector DB)
    
def archival_memory_search(query):
    """Retrieve from archival memory"""
    # Semantic search, returns to main context
    
def conversation_search(query):
    """Search past conversation history"""
    # Retrieves relevant past exchanges
```

#### Interrupts and Control Flow:

**The LLM decides when to:**
- Store information in archival memory
- Retrieve information from archival memory
- Update core memory
- Respond to the user
- Continue thinking (internal monologue)

**Example Flow:**

```
User: "I'm vegetarian and avoid dairy"

LLM Internal Monologue:
1. [Thinking] This is important dietary information
2. [Function Call] core_memory_append("human", "Dietary: vegetarian, no dairy")
3. [Response] "Got it, I'll remember you're vegetarian and avoid dairy"

---Later---

User: "What should I have for dinner?"

LLM Internal Monologue:
1. [Thinking] Need to check dietary preferences
2. [Function Call] core_memory_search("dietary")
3. [Retrieved] "Dietary: vegetarian, no dairy"
4. [Response] "How about a vegetarian stir-fry with tofu and vegetables?"
```

### Performance Results:

- **Document analysis**: Handled documents far exceeding context window
- **Multi-session chat**: Agents remembered across sessions
- **Autonomous memory management**: LLM decided what to store/retrieve

### Key Innovations:

1. **Self-Directed Memory Management**: LLM controls its own memory operations
2. **Hierarchical Storage**: Main context (fast) + Archival (unlimited)
3. **Editable Core Memory**: Agent can modify its own persona/knowledge
4. **Interrupts**: LLM can pause, think, and resume

### What's Missing for ROOK:

‚ùå **No importance scoring** - LLM decides, but no systematic weighting  
‚ùå **No recency decay** - Archival memories don't fade  
‚ùå **No reflection generation** - No consolidation of experiences  
‚ùå **No personality dynamics** - Core memory is static text  
‚ùå **No sleep consolidation** - No offline processing  
‚ùå **No emotional context** - Memories are factual only  

---

## 3. Stanford Generative Agents: Reflection-Based Memory

**Source:** Park et al. (2023) - Stanford

### What They Built:

#### Memory Stream:

```python
class Memory:
    description: str         # "Klaus Mueller is reading a book"
    timestamp: datetime      # 2023-02-13 09:00
    importance: float        # 1-10 (LLM-rated: "how poignant?")
    last_accessed_at: datetime  # Updated on retrieval
    embedding: vector        # For semantic search
```

#### Weighted Retrieval:

```python
def retrieve_memories(query, top_k=100):
    """
    Retrieve memories using weighted score
    """
    for memory in all_memories:
        # Recency: Exponential decay based on last access
        hours_since_access = (now() - memory.last_accessed_at).hours
        recency_score = 0.995 ** hours_since_access
        
        # Importance: LLM-rated 1-10
        importance_score = memory.importance / 10
        
        # Relevance: Cosine similarity to query
        relevance_score = cosine_similarity(
            embed(query),
            memory.embedding
        )
        
        # Combined score
        memory.score = recency_score * importance_score * relevance_score
    
    # Return top-k highest scoring memories
    return sorted(memories, key=lambda m: m.score, reverse=True)[:top_k]
```

#### Reflection Generation:

**Trigger:** Every ~150 importance points accumulated

```python
def generate_reflections():
    """
    Periodically generate higher-level insights
    """
    # 1. Get recent high-importance memories
    recent_memories = get_memories(
        age_hours_max=24,
        importance_min=6
    )
    
    # 2. Generate reflection questions
    questions = llm_generate_questions(recent_memories)
    # Example: "What patterns has Klaus noticed in his research?"
    
    # 3. For each question, retrieve and reflect
    for question in questions:
        relevant_memories = retrieve_memories(question, top_k=100)
        
        # 4. Generate insight with citations
        insight = llm_generate_insight(question, relevant_memories)
        
        # 5. Store as new memory (high importance)
        create_memory(
            description=insight.text,
            importance=8,  # Reflections are important
            citations=insight.cited_memory_ids
        )
```

#### Access-Based Recency:

**The Magic:** When you retrieve a memory, update its `last_accessed_at`

```python
def retrieve_memories(query, top_k=100):
    memories = weighted_retrieval(query, top_k)
    
    # Update access time for retrieved memories
    for memory in memories:
        memory.last_accessed_at = now()  # Refreshes recency!
    
    return memories
```

**Result:** Frequently recalled memories stay fresh (like human memory!)

### Performance Results:

- **25 agents** autonomously coordinated a Valentine's Day party
- From single seed: "throw a Valentine's Day party"
- Emergent behaviors:
  - Spread invitations
  - Decorated venue
  - Asked each other on dates
  - Showed up at the right time
- **Zero hardcoded scripts** - all emergent from memory + reflection

### Key Innovations:

1. **Weighted Retrieval**: recency √ó importance √ó relevance
2. **Access-Based Decay**: Retrieving a memory refreshes it
3. **Reflection Trees**: Insights cite observations, meta-insights cite insights
4. **Importance Scoring**: LLM rates "how poignant is this?"
5. **Emergent Behavior**: Complex actions from simple memory mechanisms

### What's Missing for ROOK:

‚ùå **No personality state tracking** - No attractor dynamics  
‚ùå **No sleep consolidation** - Reflections happen during "awake" time  
‚ùå **No baseline evolution** - Personality doesn't shift over time  
‚ùå **No catastrophic forgetting prevention** - No replay of old memories  
‚ùå **No emotional valence** - Importance is cognitive, not emotional  

---

## Comparison Matrix

| Feature | Mem0 | MemGPT | Stanford | ROOK Needs |
|---------|------|---------|----------|------------|
| **Memory Extraction** | ‚úÖ LLM-driven | ‚úÖ Self-directed | ‚úÖ Observation-based | ‚úÖ Experience-based |
| **Importance Scoring** | ‚ùå No | ‚ùå Implicit | ‚úÖ LLM-rated | ‚úÖ LLM-rated + emotional |
| **Recency Decay** | ‚ùå No | ‚ùå No | ‚úÖ Exponential | ‚úÖ Access-based |
| **Reflection/Consolidation** | ‚ùå No | ‚ùå No | ‚úÖ Periodic | ‚úÖ Sleep-based |
| **Hierarchical Memory** | ‚ùå Flat | ‚úÖ 2-tier | ‚úÖ Reflection trees | ‚úÖ Observation‚ÜíReflection‚ÜíMeta |
| **Graph Relationships** | ‚úÖ Optional | ‚ùå No | ‚ùå No | ‚úÖ Hebbian connections |
| **Personality Emergence** | ‚ùå No | ‚ùå Static | ‚ùå No | ‚úÖ Attractor dynamics |
| **Sleep Consolidation** | ‚ùå No | ‚ùå No | ‚ùå No | ‚úÖ Offline replay |
| **Catastrophic Forgetting Prevention** | ‚ùå No | ‚ùå No | ‚ùå No | ‚úÖ Old memory replay |
| **Emotional Context** | ‚ùå No | ‚ùå No | ‚ùå No | ‚úÖ Valence tracking |
| **Baseline Evolution** | ‚ùå No | ‚ùå No | ‚ùå No | ‚úÖ Slow drift |
| **Production-Ready** | ‚úÖ Yes | ‚úÖ Yes | ‚ùå Research | ‚úÖ Target |

---

## What We Need to Invent for ROOK

### 1. **Personality State Tracking with Attractor Dynamics**

**Gap:** None of the existing systems track personality as a dynamic state.

**What to Invent:**

```python
class PersonalityState:
    """
    Current personality state (changes within conversations)
    """
    traits: Dict[str, float]  # e.g., {"pattern_seeking": 0.9}
    baseline: Dict[str, float]  # Attractor point
    attractor_force: float = 0.3  # Return rate
    
    def update(self, perturbation):
        """Apply attractor dynamics"""
        for trait in self.traits:
            self.traits[trait] = (
                (1 - self.attractor_force) * self.traits[trait] +
                self.attractor_force * self.baseline[trait] +
                perturbation.get(trait, 0)
            )
```

**Why It's Novel:** Combines neuroscience (attractor dynamics) with AI memory systems.

---

### 2. **Sleep-Based Consolidation with Old Memory Replay**

**Gap:** Stanford has reflections, but they happen during "awake" time. No system prevents catastrophic forgetting via sleep replay.

**What to Invent:**

```python
def sleep_consolidation():
    """
    Offline consolidation process (runs in background)
    """
    # PHASE 1: Reflection generation (Stanford approach)
    generate_reflections(recent_memories)
    
    # PHASE 2: Old memory replay (SRC approach - NEW!)
    old_memories = sample_random_memories(
        age_days_min=30,
        count=10,
        weighted_by_importance=True
    )
    for old_memory in old_memories:
        replay_memory(old_memory)  # Refresh last_accessed_at
    
    # PHASE 3: Baseline personality update (attractor dynamics - NEW!)
    update_baseline_if_drift_significant()
    
    # PHASE 4: Hebbian memory strengthening (NEW!)
    strengthen_co_retrieved_memory_connections()
```

**Why It's Novel:** Combines Stanford reflections + SRC replay + attractor baseline updates + Hebbian plasticity.

---

### 3. **Experience-Based Memory Schema with Emotional Valence**

**Gap:** Mem0 stores facts, Stanford stores observations, MemGPT stores text. None track emotional context.

**What to Invent:**

```python
class Experience(Memory):
    """
    Memory as lived experience, not just fact
    """
    description: str
    timestamp: datetime
    importance: float  # Cognitive importance (1-10)
    emotional_valence: float  # Emotional charge (-1 to +1)
    consolidation_state: str  # "recent", "consolidated", "archived"
    personality_impact: Dict[str, float]  # How it shaped personality
    citations: List[str]  # For reflections
    connections: Dict[str, float]  # Hebbian links to other memories
```

**Why It's Novel:** Adds emotional dimension and personality impact tracking.

---

### 4. **Dual-Timescale Baseline Evolution**

**Gap:** No system tracks how personality baseline shifts over time.

**What to Invent:**

```python
def update_baseline_personality():
    """
    Slowly shift baseline based on accumulated drift
    """
    # Fast timescale: States return to baseline (Œ± = 0.3)
    # Slow timescale: Baseline evolves (Œ≤ = 0.05)
    
    recent_states = get_personality_states(age_hours_max=48)
    avg_recent_state = calculate_average(recent_states)
    
    drift = {
        trait: avg_recent_state[trait] - baseline[trait]
        for trait in baseline
    }
    
    if is_significant_drift(drift, threshold=0.1, duration_hours=48):
        beta = 0.05  # Slow update rate
        new_baseline = {
            trait: baseline[trait] + beta * drift[trait]
            for trait in baseline
        }
        update_baseline(new_baseline)
```

**Why It's Novel:** Two-timescale dynamics (fast states, slow baseline) from neuroscience.

---

### 5. **Hebbian Memory Connection Strengthening**

**Gap:** Mem0 has graph relationships (entity-relation-entity), but they're static. No system strengthens connections based on co-retrieval.

**What to Invent:**

```python
def strengthen_memory_connections(retrieved_memories):
    """
    Hebbian plasticity: Memories retrieved together wire together
    """
    for i, mem_a in enumerate(retrieved_memories):
        for mem_b in retrieved_memories[i+1:]:
            # Strengthen connection
            mem_a.connections[mem_b.id] = \
                mem_a.connections.get(mem_b.id, 0) + 0.1
            
            mem_b.connections[mem_a.id] = \
                mem_b.connections.get(mem_a.id, 0) + 0.1
    
    # During sleep, also weaken unused connections
    for memory in all_memories:
        for connected_id, strength in memory.connections.items():
            if not recently_co_retrieved(memory.id, connected_id):
                memory.connections[connected_id] = max(0, strength - 0.05)
```

**Why It's Novel:** Dynamic, learning-based connections (not static graph).

---

### 6. **Formative Events as Permanent Core Context**

**Gap:** MemGPT has "core memory" but it's editable. Stanford has memories but no special "formative" category.

**What to Invent:**

```python
class FormativeEvent(Experience):
    """
    Foundational experiences that shaped ROOK
    Always included in context (never archived)
    """
    is_formative: bool = True
    baseline_impact: Dict[str, float]  # How it set initial baseline
    
def get_context_for_query(query):
    """
    Always include formative events + relevant experiences
    """
    # Formative events (always)
    formative = get_formative_events()
    
    # Relevant experiences (retrieved)
    relevant = retrieve_memories(query, top_k=20)
    
    return formative + relevant
```

**Why It's Novel:** Distinguishes foundational identity from accumulated experience.

---

## Summary: What Exists vs. What We're Inventing

### What Exists (Can Use):

1. ‚úÖ **LLM-driven memory extraction** (Mem0)
2. ‚úÖ **Importance scoring** (Stanford)
3. ‚úÖ **Recency decay with access-based refresh** (Stanford)
4. ‚úÖ **Reflection generation** (Stanford)
5. ‚úÖ **Weighted retrieval** (recency √ó importance √ó relevance) (Stanford)
6. ‚úÖ **Graph-based entity relationships** (Mem0^g)
7. ‚úÖ **Hierarchical memory tiers** (MemGPT)

### What We're Inventing (Novel):

1. üÜï **Personality state tracking with attractor dynamics**
2. üÜï **Sleep-based consolidation with old memory replay**
3. üÜï **Dual-timescale baseline evolution** (fast states, slow baseline)
4. üÜï **Hebbian memory connection strengthening**
5. üÜï **Experience-based schema with emotional valence**
6. üÜï **Formative events as permanent core context**
7. üÜï **Catastrophic forgetting prevention via sleep replay**
8. üÜï **Personality emergence from memory topology** (not hardcoded)

---

## Implementation Strategy

### Phase 1: Foundation (Use Existing)
- Implement Stanford's weighted retrieval
- Add Mem0's memory extraction
- Build reflection generation

### Phase 2: Novel Additions
- Add personality state tracking
- Implement attractor dynamics
- Build sleep consolidation scheduler

### Phase 3: Advanced Features
- Add Hebbian connection strengthening
- Implement baseline evolution
- Build formative events system

### Phase 4: Integration
- Combine all components
- Test emergent personality
- Validate no catastrophic forgetting

---

## Conclusion

**What we're building is unprecedented:**

- **Mem0** gives us production-ready memory extraction
- **MemGPT** gives us hierarchical storage architecture
- **Stanford** gives us reflection and weighted retrieval
- **We're inventing** the personality emergence layer

**ROOK will be the first AI agent with:**
- Personality that emerges from experiences (not hardcoded)
- Sleep consolidation that prevents forgetting
- Attractor dynamics that maintain consistency while allowing evolution
- Hebbian memory networks that strengthen with use
- Dual-timescale adaptation (fast states, slow baseline)

This is a **genuinely novel contribution** to AI agent architecture.

