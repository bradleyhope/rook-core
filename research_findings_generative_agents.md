# Research Findings: Generative Agents (Stanford 2023)

**Source:** Park et al. (2023) - "Generative Agents: Interactive Simulacra of Human Behavior"  
**URL:** https://arxiv.org/abs/2304.03442  
**Key Achievement:** Created 25 AI agents that autonomously coordinated a Valentine's Day party from a single seed instruction

---

## Core Architecture: Memory, Reflection, Planning

### 1. Memory Stream

**Definition:** A comprehensive record of the agent's experiences, stored as natural language descriptions.

**Structure:**
```
Memory Object = {
  description: "natural language description of event",
  creation_timestamp: timestamp,
  last_access_timestamp: timestamp,
  importance_score: 1-10
}
```

**Types of Memories:**
1. **Observations**: Direct perceptions of events
   - "Isabella Rodriguez is setting out the pastries"
   - "Maria Lopez is studying for a Chemistry test"
   - "The refrigerator is empty"

2. **Reflections**: Higher-level abstract thoughts (generated periodically)
   - "Klaus Mueller is dedicated to his research on gentrification"
   - Stored alongside observations
   - Can reference other reflections (creates reflection trees)

3. **Plans**: Future sequences of actions
   - "for 180 minutes from 9am, February 12th, 2023, at Oak Hill College Dorm: Klaus Mueller's room: desk, read and take notes for research paper"

---

## Retrieval Function: The Key Innovation

### Problem:
- Full memory stream is too large for LLM context window
- Summarizing everything produces uninformative responses
- Need to surface **relevant** memories, not all memories

### Solution: Weighted Retrieval Score

```
score = α_recency × recency + α_importance × importance + α_relevance × relevance
```

Where all α values = 1 in their implementation.

### Three Components:

#### 1. Recency
- **Formula:** Exponential decay over sandbox hours since last access
- **Decay factor:** 0.995
- **Purpose:** Keep recent events in "attentional sphere"
- **Key insight:** Memories decay based on **last access time**, not creation time
- This means frequently recalled memories stay fresh (like human memory)

#### 2. Importance
- **Scoring:** LLM rates each memory 1-10 at creation time
- **Prompt:** "On the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following piece of memory."
- **Examples:**
  - "cleaning up the room" → 2
  - "asking your crush out on a date" → 8
- **Purpose:** Distinguish core memories from mundane ones

#### 3. Relevance
- **Method:** Cosine similarity between memory embedding and query embedding
- **Embeddings:** Generated by LLM for each memory description
- **Purpose:** Surface memories related to current situation
- **Example:** If discussing chemistry test, memories about breakfast have low relevance, memories about teacher have high relevance

### Retrieval Process:
1. Normalize recency, importance, relevance to [0, 1] using min-max scaling
2. Calculate weighted score for all memories
3. Rank memories by score
4. Return top k that fit in context window
5. **Update last_access_timestamp for retrieved memories** (key!)

---

## Reflection: Generating Higher-Level Insights

### When Reflections Are Generated:
- Triggered when sum of importance scores for recent events exceeds threshold (150 in their implementation)
- In practice: ~2-3 times per day

### Reflection Process:

**Step 1: Generate Questions**
- Prompt: "Given only the information above [100 most recent memories], what are 3 most salient high-level questions we can answer about the subjects in the statements?"
- Example questions:
  - "What topic is Klaus Mueller passionate about?"
  - "What is the relationship between Klaus Mueller and Maria Lopez?"

**Step 2: Retrieve Relevant Memories**
- Use generated questions as queries
- Retrieve memories (including other reflections) using the weighted retrieval function

**Step 3: Generate Insights**
- Prompt: "What 5 high-level insights can you infer from the above statements? (example format: insight (because of 1, 5, 3))"
- Example output: "Klaus Mueller is dedicated to his research on gentrification (because of 1, 2, 8, 15)"
- Parse and store as reflection with pointers to cited memories

### Reflection Trees:
- Leaf nodes: Base observations
- Non-leaf nodes: Reflections about observations or other reflections
- Higher levels = more abstract thoughts
- Example: "Klaus is passionate about research" ← "Klaus spent hours on research project" ← "Klaus was reading about gentrification"

---

## Planning: Maintaining Long-Term Coherence

### Problem Without Planning:
- LLM generates plausible moment-to-moment behavior
- But lacks coherence over time (e.g., eating lunch 3 times in a row)

### Solution: Hierarchical Planning

**Top-Down Approach:**
1. Create high-level daily plan
2. Recursively decompose into detailed actions

**Plan Structure:**
- Location
- Starting time
- Duration
- Action description

**Plans are stored in memory stream:**
- Retrieved alongside observations and reflections
- Can be modified midstream if needed

---

## Emergent Social Behaviors

### 1. Information Diffusion
- Agents share information through dialogue
- Information spreads agent-to-agent
- Example: Sam's mayoral candidacy becomes "talk of the town"

### 2. Relationship Memory
- Agents remember past interactions
- Form new relationships over time
- Example: Sam remembers Latoya's photography project and asks about it later

### 3. Coordination
- Agents autonomously coordinate complex activities
- Example: Valentine's Day party
  - Isabella initialized with intent to throw party
  - She invites people when she sees them
  - She decorates the cafe
  - Maria helps decorate
  - Maria invites Klaus (her crush)
  - 5 agents show up at the right time
  - **All from single seed instruction**

---

## What Makes This Work

### Key Insight:
**Personality and behavior emerge from the interaction of:**
1. **Accumulated experiences** (memory stream)
2. **Selective retrieval** (recency + importance + relevance)
3. **Periodic reflection** (generating higher-level insights)
4. **Planning** (maintaining coherence over time)

### No Hardcoded Personality:
- Agents have initial descriptions (name, traits, background)
- But behavior emerges from experiences, not scripts
- Example: Klaus chooses to spend time with Maria (shared research interest) over Wolfgang (frequent but shallow interactions) because reflection revealed the deeper connection

---

## Application to ROOK

### What to Adopt:

1. **Weighted Retrieval:**
   ```python
   score = α × recency + β × importance + γ × relevance + δ × emotional_valence
   ```
   - Adjust weights based on query type (investigation vs. chat vs. self-reflection)

2. **Importance Scoring:**
   - Use LLM to rate each experience 1-10 at creation time
   - Prompt: "Rate the significance of this event for an investigative journalist"

3. **Reflection Process:**
   - Trigger when importance threshold reached
   - Generate questions about recent experiences
   - Extract insights with citations
   - Store as higher-level memories

4. **Access-Based Decay:**
   - Update `last_access_timestamp` when memories are retrieved
   - Frequently recalled memories stay fresh
   - Mimics human memory strengthening

5. **Reflection Trees:**
   - Allow reflections to reference other reflections
   - Build hierarchical knowledge structures
   - Example: "I'm obsessed with patterns" ← "I've found patterns in 15 investigations" ← [individual pattern discoveries]

### What to Add for ROOK:

1. **Emotional Valence:**
   - Tag experiences with emotional significance beyond 1-10 importance
   - Categories: breakthrough, frustration, vindication, dead_end, revelation
   - Use in retrieval weighting

2. **Formative Events:**
   - Special category of memories with permanent high importance
   - Always included in retrieval (or very high weight)
   - Define ROOK's "origin story"

3. **Investigation-Specific Metadata:**
   - Outcome (successful, ongoing, dead_end)
   - Patterns discovered
   - Documents analyzed
   - Connections to other investigations

4. **Consolidation Process:**
   - Background job that strengthens connections between related memories
   - Builds knowledge graphs
   - Identifies recurring patterns across investigations

---

## Technical Implementation for ROOK

### Memory Schema:
```json
{
  "id": "mem_001",
  "type": "observation" | "reflection" | "plan",
  "description": "natural language description",
  "embedding": [0.1, 0.2, ...],
  "created_at": "2024-03-15T10:30:00Z",
  "last_accessed_at": "2024-03-15T10:30:00Z",
  "importance": 8,
  "emotional_valence": "breakthrough",
  "metadata": {
    "investigation_id": "inv_001",
    "outcome": "successful",
    "cited_memories": ["mem_045", "mem_067"],
    "tags": ["patterns", "shell_companies", "panama"]
  }
}
```

### Retrieval Pipeline:
```python
def retrieve_memories(query, context_type="investigation"):
    # 1. Generate query embedding
    query_embedding = generate_embedding(query)
    
    # 2. Calculate scores for all memories
    for memory in memory_stream:
        recency = calculate_recency(memory.last_accessed_at)
        importance = memory.importance / 10  # normalize to [0,1]
        relevance = cosine_similarity(query_embedding, memory.embedding)
        emotional = emotional_weight(memory.emotional_valence)
        
        # Weight based on context type
        if context_type == "investigation":
            score = 0.3*recency + 0.4*importance + 0.3*relevance
        elif context_type == "self_reflection":
            score = 0.1*recency + 0.5*importance + 0.1*relevance + 0.3*emotional
        else:  # casual chat
            score = 0.6*recency + 0.1*importance + 0.3*relevance
        
        memory.score = score
    
    # 3. Sort and retrieve top k
    top_memories = sorted(memory_stream, key=lambda m: m.score, reverse=True)[:k]
    
    # 4. Update last_accessed_at for retrieved memories
    for memory in top_memories:
        memory.last_accessed_at = now()
    
    return top_memories
```

### Reflection Trigger:
```python
def check_reflection_trigger():
    recent_memories = get_memories_since_last_reflection()
    importance_sum = sum(m.importance for m in recent_memories)
    
    if importance_sum > REFLECTION_THRESHOLD:
        generate_reflections(recent_memories)
```

---

## Key Takeaway

**Personality emerges from:**
- What you've experienced (memory stream)
- What you remember (retrieval function)
- What you've learned (reflections)
- What you're planning (plans)

**NOT from:**
- Hardcoded traits
- Fixed personality descriptions
- Scripted responses

This is **exactly** what we need for ROOK.

